---
layout: post
title: "生成式 AI 應用開發的常見錯誤"
date: 2025-02-11 10:00:00 +0800
categories: ['NotionExport']
math: true
---

📌 文章來源 https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html[https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html](https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html)📌 文章來源 https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html[https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html](https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html)

## ❶ 不該用生成式 AI 的場景，硬要用生成式 AI 🤖❶ 不該用生成式 AI 的場景，硬要用生成式 AI 🤖

大語言模型（LLM）確實強大，但它並不適用於所有場景。然而，許多人對這項技術的能力缺乏理解，強行將 LLM 用於不合適的應用，例如：大語言模型（LLM）確實強大，但它並不適用於所有場景。然而，許多人對這項技術的能力缺乏理解，強行將 LLM 用於不合適的應用，例如：

- 能源消耗最佳化能源消耗最佳化
- 流量異常檢測流量異常檢測
- 電量預測電量預測
- 病人營養不良檢測病人營養不良檢測
這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。，而非 LLM。這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。，而非 LLM。這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。，而非 LLM。這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。，而非 LLM。這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。，而非 LLM。

🔹 我曾遇過公司想用 LLM 進行營運最佳化和異常檢測，結果發現資料全是數字型態。這類問題根本不應該用 LLM，而應該使用適合的數據分析工具或機器學習方法。🔹 我曾遇過公司想用 LLM 進行營運最佳化和異常檢測，結果發現資料全是數字型態。這類問題根本不應該用 LLM，而應該使用適合的數據分析工具或機器學習方法。

---

### ❷ 搞混「爛 AI 產品」與「笨 AI 模型」 🤦‍♂️❷ 搞混「爛 AI 產品」與「笨 AI 模型」 🤦‍♂️

很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。。很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。。很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。。很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。。很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。。

舉例來說，目前市面上的 AI 代碼助手，如：舉例來說，目前市面上的 AI 代碼助手，如：

- GitHub CopilotGitHub Copilot
- CursorCursor
- WindsurfWindsurf
- DevinDevin
這些產品大多使用相同的 LLM，真正的差異在於：這些產品大多使用相同的 LLM，真正的差異在於：

1. 產品設計是否優秀產品設計是否優秀
1. 是否具備良好的 AI 工程能力是否具備良好的 AI 工程能力
  - Prompt ChainingPrompt Chaining

  - 檢索增強生成（RAG）檢索增強生成（RAG）

  - 模型上下文管理模型上下文管理

- Prompt ChainingPrompt Chaining
- 檢索增強生成（RAG）檢索增強生成（RAG）
- 模型上下文管理模型上下文管理
如果沒有這些技術，無論模型多強，最終的產品體驗都會很糟糕。如果沒有這些技術，無論模型多強，最終的產品體驗都會很糟糕。

📌 關鍵觀念：「原始智力」≠「智慧軟體系統」關鍵觀念：「原始智力」≠「智慧軟體系統」📌 關鍵觀念：「原始智力」≠「智慧軟體系統」關鍵觀念：「原始智力」≠「智慧軟體系統」

LLM 只是基石，真正有效的 AI 系統還需要：LLM 只是基石，真正有效的 AI 系統還需要：

- 上下文管理上下文管理
- 工具整合工具整合
- 成熟的工程化流程成熟的工程化流程
這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。這也符合 Berkeley AI Research (BAIR) 提出的 The Shift from Models to Compound AI Systems，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。，而非單純依賴 LLM。

---

### ❸ 一開始就搞得太複雜 🏗️❸ 一開始就搞得太複雜 🏗️

許多團隊過早地引入不必要的複雜技術，導致系統難以維護。例如：許多團隊過早地引入不必要的複雜技術，導致系統難以維護。例如：

❌ 不需要時就使用 Agent 框架不需要時就使用 Agent 框架❌ 不需要時就使用 Agent 框架不需要時就使用 Agent 框架

❌ 糾結於選擇向量資料庫，而忽略基礎需求糾結於選擇向量資料庫，而忽略基礎需求❌ 糾結於選擇向量資料庫，而忽略基礎需求糾結於選擇向量資料庫，而忽略基礎需求

❌ 明明透過 Prompting 就足夠，卻堅持要 Fine-tuning明明透過 Prompting 就足夠，卻堅持要 Fine-tuning❌ 明明透過 Prompting 就足夠，卻堅持要 Fine-tuning明明透過 Prompting 就足夠，卻堅持要 Fine-tuning

這些做法往往會：這些做法往往會：

- 增加開發難度增加開發難度
- 抽象掉關鍵細節抽象掉關鍵細節
- 讓系統更難理解和除錯讓系統更難理解和除錯
📌 建議：先用最簡單的方法解決問題，確保技術選擇符合需求，而非為了技術而技術。建議：先用最簡單的方法解決問題，確保技術選擇符合需求，而非為了技術而技術。📌 建議：先用最簡單的方法解決問題，確保技術選擇符合需求，而非為了技術而技術。建議：先用最簡單的方法解決問題，確保技術選擇符合需求，而非為了技術而技術。

---

### ❹ 過度樂觀看待初期成功 🎢❹ 過度樂觀看待初期成功 🎢

許多 AI 團隊在早期取得不錯的成果後，容易產生過度樂觀的錯誤判斷。例如：許多 AI 團隊在早期取得不錯的成果後，容易產生過度樂觀的錯誤判斷。例如：

🔹 LinkedIn AI 產品開發經驗LinkedIn AI 產品開發經驗🔹 LinkedIn AI 產品開發經驗LinkedIn AI 產品開發經驗

- 從 0 到 80% 只花 1 個月從 0 到 80% 只花 1 個月
- 從 80% 到 95% 卻花了 4 個月從 80% 到 95% 卻花了 4 個月
- 最後 10-20% 的優化往往最困難最後 10-20% 的優化往往最困難
🎯 重點：做出 Demo 很容易，但真正要上線的產品極具挑戰！重點：做出 Demo 很容易，但真正要上線的產品極具挑戰！🎯 重點：做出 Demo 很容易，但真正要上線的產品極具挑戰！重點：做出 Demo 很容易，但真正要上線的產品極具挑戰！

後期會遇到：後期會遇到：

- 幻覺問題（Hallucination）幻覺問題（Hallucination）
- 延遲延遲
- 準確性與效能的權衡準確性與效能的權衡
- Prompt 設計Prompt 設計
- 模型評估模型評估
🔹 千萬不要因為初期的成功，而忽視後期的挑戰！🔹 千萬不要因為初期的成功，而忽視後期的挑戰！

---

### ❺ 忽視人工評估 🧐❺ 忽視人工評估 🧐

目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。

✅ 人工評估的重要性人工評估的重要性✅ 人工評估的重要性人工評估的重要性

1. 驗證 AI 評估結果的準確性驗證 AI 評估結果的準確性
1. 了解實際用戶的使用情況了解實際用戶的使用情況
1. 及早發現異常模式及早發現異常模式
📌 建議：AI 評估 + 人工抽樣，雙管齊下才能確保模型可靠性！建議：AI 評估 + 人工抽樣，雙管齊下才能確保模型可靠性！📌 建議：AI 評估 + 人工抽樣，雙管齊下才能確保模型可靠性！建議：AI 評估 + 人工抽樣，雙管齊下才能確保模型可靠性！

---

### ❻ 盲目蒐集使用案例 📋❻ 盲目蒐集使用案例 📋

許多企業在 AI 數位轉型時，缺乏明確的目標，只是因為知道 LLM 很強，就盲目探索應用場景，導致：許多企業在 AI 數位轉型時，缺乏明確的目標，只是因為知道 LLM 很強，就盲目探索應用場景，導致：

❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論最終得出「生成式 AI 投資報酬率不高」的結論

🔹 建議：建議：🔹 建議：建議：

1. 確定核心業務需求確定核心業務需求
1. 建立清晰的 AI 應用策略建立清晰的 AI 應用策略
1. 專注在真正能帶來高價值的應用專注在真正能帶來高價值的應用
這樣才能讓 AI 投資獲得最大回報，避免無謂的資源浪費。這樣才能讓 AI 投資獲得最大回報，避免無謂的資源浪費。

---

## 🎯 總結：如何避免 AI 工程的 6 大陷阱？🎯 總結：如何避免 AI 工程的 6 大陷阱？

| 陷阱陷阱 | 主要問題主要問題 | 解決方案解決方案 |
| --- | --- | --- |
| ❶ 濫用生成式 AI❶ 濫用生成式 AI | LLM 不適用所有場景LLM 不適用所有場景 | 使用專門的機器學習與演算法使用專門的機器學習與演算法 |
| ❷ 以為 AI 產品爛是因為模型笨❷ 以為 AI 產品爛是因為模型笨 | 其實是工程能力不足其實是工程能力不足 | 強化 Prompting、RAG、上下文管理強化 Prompting、RAG、上下文管理 |
| ❸ 一開始就搞得太複雜❸ 一開始就搞得太複雜 | 過早引入不必要的工具過早引入不必要的工具 | 先用最簡單的方法解決問題先用最簡單的方法解決問題 |
| ❹ 過度樂觀初期成功❹ 過度樂觀初期成功 | 低估最後 10-20% 的難度低估最後 10-20% 的難度 | 預留足夠時間進行優化預留足夠時間進行優化 |
| ❺ 忽視人工評估❺ 忽視人工評估 | LLM 自評不夠準確LLM 自評不夠準確 | 結合人工抽樣，提高評估準確性結合人工抽樣，提高評估準確性 |
| ❻ 盲目蒐集使用案例❻ 盲目蒐集使用案例 | 缺乏明確策略，導致資源浪費缺乏明確策略，導致資源浪費 | 聚焦高價值應用，建立清晰 AI 策略聚焦高價值應用，建立清晰 AI 策略 |

📌 AI 工程不僅是 LLM 的應用，還涉及上下文管理、產品設計、工程能力、評估機制與策略規劃。希望這些建議能幫助你在 AI 領域少走彎路，打造真正有價值的 AI 產品！🚀AI 工程不僅是 LLM 的應用，還涉及上下文管理、產品設計、工程能力、評估機制與策略規劃。希望這些建議能幫助你在 AI 領域少走彎路，打造真正有價值的 AI 產品！🚀📌 AI 工程不僅是 LLM 的應用，還涉及上下文管理、產品設計、工程能力、評估機制與策略規劃。希望這些建議能幫助你在 AI 領域少走彎路，打造真正有價值的 AI 產品！🚀AI 工程不僅是 LLM 的應用，還涉及上下文管理、產品設計、工程能力、評估機制與策略規劃。希望這些建議能幫助你在 AI 領域少走彎路，打造真正有價值的 AI 產品！🚀
