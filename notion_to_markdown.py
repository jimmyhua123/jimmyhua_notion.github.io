import os
import requests
import datetime
import re
import glob
import unicodedata
from urllib.parse import urlparse

# ----------------------------------------------------------------------
# 1. è®€å– Notion Token & Page ID è¨­å®š
# ----------------------------------------------------------------------

NOTION_TOKEN = "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"
# NOTION_TOKEN = os.environ["NOTION_TOKEN"] 
ROOT_PAGE_ID = "166fbb857f9e80eba96ef0091d6ce244"  # ä½ çš„æœ€ä¸Šå±¤ Notion Page ID

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28"
}

processed_pages = set()

def slugify(text):
    """
    è½‰æ›æ¨™é¡Œç‚ºæª”æ¡ˆåç¨±å‹å–„æ ¼å¼ï¼š
    - ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿ
    - è½‰æ›ç‚ºå°å¯«
    - ç©ºæ ¼è®Šæˆ "-"
    """
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'[^\w\s-]', '', text).strip().lower()
    return re.sub(r'[-\s]+', '-', text)

# ----------------------------------------------------------------------
# 2. å–å¾—é é¢æ¨™é¡Œ (é¸æ“‡ç”¨ retrieve_pageï¼Œæˆ–ç›´æ¥å¾ child_page["title"] å–)
# ----------------------------------------------------------------------
def retrieve_page_title(page_id: str) -> tuple:
    """
    ç²å– Notion é é¢æ¨™é¡Œï¼Œä¸¦ç”¢ç”Ÿ `slug`
    """
    url = f"https://api.notion.com/v1/pages/{page_id}"
    try:
        res = requests.get(url, headers=HEADERS)
        data = res.json()
        title_obj = data["properties"]["title"]["title"]
        if title_obj:
            page_title = title_obj[0]["plain_text"]
            return page_title, slugify(page_title)  # âš¡ï¸ å›å‚³ slug
    except (KeyError, IndexError, requests.exceptions.RequestException) as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–é é¢æ¨™é¡Œï¼š{e}")
    return "Untitled", "untitled"

# ----------------------------------------------------------------------
# 3. å–å¾—æŸé é¢ä¸‹çš„æ‰€æœ‰å€å¡Š (å«åˆ†é è™•ç†)
# ----------------------------------------------------------------------
def fetch_notion_blocks(page_id: str) -> list:
    """
    å›å‚³æŒ‡å®š page_id çš„ç›´æ¥ children å€å¡Šï¼Œä¸é€²è¡Œéè¿´
    """
    all_blocks = []
    base_url = "https://api.notion.com/v1/blocks"
    url = f"{base_url}/{page_id}/children"
    params = {}
    while True:
        resp = requests.get(url, headers=HEADERS, params=params)
        data = resp.json()
        all_blocks.extend(data.get("results", []))
        if data.get("has_more"):
            params["start_cursor"] = data["next_cursor"]
        else:
            break
    return all_blocks

# ----------------------------------------------------------------------
# 4. ä¸‹è¼‰åœ–ç‰‡ä¸¦å„²å­˜åˆ°æœ¬æ©Ÿ
# ----------------------------------------------------------------------
def download_image(image_url: str, block_id: str) -> str:
    images_dir = "images"
    if not os.path.exists(images_dir):
        os.makedirs(images_dir)
    parsed_url = urlparse(image_url)
    path = parsed_url.path
    ext = os.path.splitext(path)[1]
    if not ext:
        ext = ".jpg"
    local_filename = f"{block_id}{ext}"
    local_path = os.path.join(images_dir, local_filename)
    if not os.path.exists(local_path):
        try:
            r = requests.get(image_url, stream=True, timeout=10)
            if r.status_code == 200:
                with open(local_path, "wb") as f:
                    for chunk in r.iter_content(1024):
                        f.write(chunk)
                print(f"ä¸‹è¼‰åœ–ç‰‡æˆåŠŸ: {local_path}")
            else:
                print(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {image_url}ï¼Œç‹€æ…‹ç¢¼: {r.status_code}")
        except Exception as e:
            print(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {image_url}ï¼ŒéŒ¯èª¤: {e}")
    else:
        print(f"åœ–ç‰‡å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰: {local_path}")
    return f"{{{{ site.baseurl }}}}/images/{local_filename}"


def rich_text_array_to_markdown(rich_text_array: list) -> str:
    md_text_parts = []
    inline_math_pattern = re.compile(r'\$(.+?)\$')
    
    for rt in rich_text_array:
        text_content = rt.get("plain_text", "")
        def replace_math(match):
            content = match.group(1)
            if content.startswith('$') and content.endswith('$'):
                return match.group(0)
            return "$$" + content + "$$"
        new_text = inline_math_pattern.sub(replace_math, text_content)
        link_url = None
        if rt.get("href"):
            link_url = rt.get("href")
        elif rt.get("text") and rt["text"].get("link"):
            link_url = rt["text"]["link"].get("url")
        if link_url:
            md_text_parts.append(f"[{new_text}]({link_url})")
        else:
            md_text_parts.append(new_text)
    return "".join(md_text_parts)

def block_to_markdown(block: dict, article_title: str = "untitled") -> str:
    btype = block.get("type", "")
    # æ®µè½
    if btype == "paragraph":
        texts = block[btype].get("rich_text", [])
        return rich_text_array_to_markdown(texts) + "\n\n"
    # æ¨™é¡Œ
    elif btype == "heading_1":
        texts = block[btype].get("rich_text", [])
        return f"# {rich_text_array_to_markdown(texts)}\n\n"
    elif btype == "heading_2":
        texts = block[btype].get("rich_text", [])
        return f"## {rich_text_array_to_markdown(texts)}\n\n"
    elif btype == "heading_3":
        texts = block[btype].get("rich_text", [])
        return f"### {rich_text_array_to_markdown(texts)}\n\n"
    # æ¸…å–®ï¼šåƒ…å–å¾—ç›´æ¥å­å€å¡Šï¼Œéè¿´è™•ç†å­å€å¡Š
    elif btype == "bulleted_list_item":
        texts = block[btype].get("rich_text", [])
        list_text = rich_text_array_to_markdown(texts)
        if block.get("has_children", False):
            child_blocks = fetch_notion_blocks(block["id"])
            child_texts = [block_to_markdown(child) for child in child_blocks]
            sub_content = "\n  ".join(child_texts)
            return f"- {list_text}\n  {sub_content}\n"
        else:
            return f"- {list_text}\n"
    elif btype == "numbered_list_item":
        texts = block[btype].get("rich_text", [])
        list_text = rich_text_array_to_markdown(texts)
        if block.get("has_children", False):
            child_blocks = fetch_notion_blocks(block["id"])
            child_texts = [block_to_markdown(child) for child in child_blocks]
            sub_content = "\n  ".join(child_texts)
            return f"1. {list_text}\n  {sub_content}\n"
        else:
            return f"1. {list_text}\n"
    # æ•¸å­¸æ–¹ç¨‹å¼
    elif btype == "equation":
        equation_text = block[btype].get("expression", "")
        return f"$$\n{equation_text}\n$$\n\n"
    # ç¨‹å¼ç¢¼
    elif btype == "code":
        texts = block[btype].get("rich_text", [])
        code_text = "".join(rich_text_array_to_markdown([t]) for t in texts)
        language = block[btype].get("language", "plaintext")
        return f"```{language}\n{code_text}\n```\n\n"
    # åœ–ç‰‡
    elif btype == "image":
        image_data = block[btype]
        if image_data.get("type") == "external":
            url = image_data["external"].get("url", "")
        else:
            url = image_data["file"].get("url", "")
        local_url = download_image(url, block["id"])
        return f"![image]({local_url})\n\n"
    # åˆ†éš”ç·š
    elif btype == "divider":
        return "---\n\n"
    # å¼•è¨€
    elif btype == "quote":
        texts = block[btype].get("rich_text", [])
        return f"> {rich_text_array_to_markdown(texts)}\n\n"
    # è¡¨æ ¼
    elif btype == "table":
        table_info = block.get("table", {})
        table_width = table_info.get("table_width", 3)
        if block.get("has_children", False):
            table_rows = fetch_notion_blocks(block["id"])
        else:
            return ""
        md_table = []
        for row in table_rows:
            if row["type"] == "table_row":
                cells = row["table_row"].get("cells", [])
                md_row = " | ".join(rich_text_array_to_markdown(cell) for cell in cells)
                md_table.append(f"| {md_row} |")
        if md_table:
            separator = "| " + " | ".join(["---"] * table_width) + " |"
            md_table.insert(1, separator)
        return "\n".join(md_table) + "\n\n"
    # child_page èˆ‡ child_database ä¸åœ¨æ­¤è™•ç†
    elif btype in ["child_page", "child_database"]:
        return ""
    return ""

def upsert_post_with_date_update(slug, title, new_markdown, categories=None):
    if not os.path.exists("_posts"):
        os.makedirs("_posts")

    # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰è©²æ¨™é¡Œçš„æ–‡ç« 
    existing_files = glob.glob(f"_posts/*-{slug}.md")
    if existing_files:
        filename = existing_files[0]
        with open(filename, "r", encoding="utf-8") as f:
            old_full_content = f.read()
    else:
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        filename = f"_posts/{today_str}-{slug}.md"
        old_full_content = ""

    # åˆªé™¤é‡è¤‡æª”æ¡ˆ
    for file in existing_files:
        if file != filename:
            os.remove(file)
            print(f"âš ï¸ åˆªé™¤é‡è¤‡æª”æ¡ˆï¼š{file}")

    # æå–èˆŠçš„ front matter èˆ‡å…§å®¹
    match = re.search(r"(?s)^---(.*?)---(.*)$", old_full_content)
    if match:
        old_front = match.group(1).strip()
        old_body = match.group(2).strip()
    else:
        old_front = ""
        old_body = old_full_content.strip()

    # æ­£ç¢ºè¨­å®š dateï¼Œåªåœ¨å…§å®¹æ›´æ–°æ™‚æ‰æ›´æ–° date
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    new_date = f"{today_str} 10:00:00 +0800"
    
    # æ›´æ–° front matterï¼ˆä¿ç•™å…¶ä»–æ¬„ä½ï¼Œä½†ä¸è¦†è“‹ dateï¼‰
    front_matter_dict = {
        "layout": "post",
        "title": f'"{title}"',
        "categories": categories if categories else ["NotionExport"],
        "math": "true"
    }
    if old_front:
        for line in old_front.split("\n"):
            key, *value = line.split(":", 1)
            key = key.strip()
            if key != "date" and value:
                front_matter_dict[key] = value[0].strip()
    
    # å¦‚æœå…§å®¹æœ‰æ›´æ–°ï¼Œæ‰æ›´æ–° date
    if old_body != new_markdown.strip():
        front_matter_dict["date"] = new_date
    
    updated_front_matter = "---\n" + "\n".join(f"{key}: {value}" for key, value in front_matter_dict.items()) + "\n---\n"
    updated_full = updated_front_matter + "\n" + new_markdown.strip() + "\n"

    if old_body != new_markdown.strip():
        with open(filename, "w", encoding="utf-8") as f:
            f.write(updated_full)
        print(f"[UPDATE] {filename} å…§å®¹è®Šæ›´ï¼Œæ—¥æœŸå·²æ›´æ–°")
    else:
        print(f"[NO CHANGE] {filename} å…§å®¹æœªè®Šæ›´ï¼Œæ—¥æœŸä¿æŒåŸæ¨£")

processed_pages = set()
def parse_and_export_recursively(page_id: str, parent_slug: str = None):
    global processed_pages
    if page_id in processed_pages:
        print(f"âš ï¸ é é¢ {page_id} å·²è™•ç†ï¼Œè·³é")
        return
    processed_pages.add(page_id)
    page_title, slug = retrieve_page_title(page_id)
    if parent_slug:
        slug = f"{parent_slug}-{slug}"
    blocks = fetch_notion_blocks(page_id)
    page_markdown_parts = []
    child_pages = []
    for block in blocks:
        if block.get("type") == "child_page":
            child_pages.append(block)
        else:
            page_markdown_parts.append(block_to_markdown(block, article_title=page_title))
    page_markdown = "".join(page_markdown_parts)
    if not child_pages:
        upsert_post_with_date_update(slug, page_title, page_markdown, categories=["NotionExport"])
    for child_block in child_pages:
        child_id = child_block["id"]
        parse_and_export_recursively(child_id, parent_slug=slug)

# ä»¥ä¸‹çœç•¥ retrieve_page_title èˆ‡ upsert_post_with_date_update ç­‰å…¶ä»–å‡½å¼...
# ä¸»ç¨‹å¼åŸ·è¡Œ
def main():
    print("ğŸš€ é–‹å§‹åŒ¯å‡º Notion å…§å®¹...")
    try:
        parse_and_export_recursively(ROOT_PAGE_ID)
        print("ğŸ‰ å…¨éƒ¨é é¢åŒ¯å‡ºå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ç™¼ç”Ÿï¼š{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()