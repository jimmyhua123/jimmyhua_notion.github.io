---
layout: post
title: "5. May: LoRA learns less and forgets less"
categories: ['NotionExport']
math: true
date: 2025-02-28 10:00:00 +0800
---

在微調大型語言模型 (LLM) 時，常見的方法有 完整微調 (Full Finetuning) 和 LoRA (Low-Rank Adaptation, 低秩適應)。這兩者在記憶體需求、效能、遺忘程度和適用場景上各有優勢。



---

## 完整微調 (Full Finetuning)

### 🔹 定義

更新 LLM 中的所有參數，使其適應特定的任務或資料集。

### 🔹 運作方式

- 調整 LLM 內每個權重矩陣 $$W$$，並計算一個大型的權重更新矩陣 $$\Delta W$$。
### 🔹 適用場景

✅ 吸收新知識：適用於程式碼等需要學習大量新知識的任務，通常比 LoRA 更有效。

✅ 最大化學習能力：適用於需要最高效能的場景。

### 🔹 優點

✔ 高效能：在適當條件下，可達到最佳效能。

### 🔹 缺點

❌ 資源需求高：需要更新所有參數，消耗大量 GPU 記憶體。

❌ 容易遺忘 (災難性遺忘)：學習新任務時，可能會忘記先前的知識。

❌ 權衡問題：需在學習新知識與避免遺忘之間做出選擇。

❌ 高秩擾動：完整微調的權重變動通常高於 LoRA 配置。



---

## LoRA (低秩適應, Low-Rank Adaptation)

### 🔹 定義

一種參數高效微調技術，僅訓練部分權重矩陣的低秩擾動，以降低記憶體需求。

### 🔹 運作方式

- 在模型的權重矩陣 $$W$$ 旁，引入 低秩矩陣 $$A$$ 和 $$B$$。
- 初始化方式：
  - $$A$$ 使用均勻的 Kaiming 分佈 初始化。

  - $$B$$ 初始化為零，確保 $$\Delta W = BA = 0$$。

- $$r$$ (秩值) 控制可調整的參數數量。
### 🔹 適用場景

✅ 資源有限的環境：顯著減少記憶體使用量，使其更適合低資源場景。

✅ 減少遺忘：比完整微調更能保留原始模型知識。

✅ 專門應用：如果只需適應特定應用，LoRA 可能足夠。

### 🔹 優點

✔ 資源效率高：僅訓練少量參數，降低記憶體與計算需求。

✔ 減少遺忘：比完整微調更能保留來源領域效能。

✔ 多樣性：可維持更多樣化的生成結果。

### 🔹 缺點

❌ 效能可能較低：在需要學習大量新知識的情境下，LoRA 的表現可能不如完整微調。

❌ 超參數敏感性高：LoRA 效能高度依賴學習率、秩值等超參數的調整。

❌ 訓練速度較慢：若使用固定批次大小，LoRA 的訓練時間可能較長。

❌ 低秩假設限制：完整微調的權重擾動通常高於 LoRA 設計的低秩範圍，影響其效能。



---

## 🔍 完整微調 vs. LoRA：比較表

| 特性 | 完整微調 | LoRA (低秩適應) |
| --- | --- | --- |
| 參數更新 | 更新所有參數 | 僅訓練少量額外參數 (低秩擾動) |
| 記憶體需求 | 高 | 低 |
| 學習能力 | 強，適合學習新知識 | 弱，但仍有效 |
| 遺忘程度 | 容易遺忘先前知識 | 更能保留先前知識 |
| 適用場景 | 追求極致效能，資源充足，可容忍遺忘 | 資源有限，需保留先前知識，或針對特定應用 |
| 權重變動 | 高秩變動 | 低秩假設 |
| 超參數敏感度 | 低 | 高 |
| 訓練速度 | 較快 | 較慢 |



---

## 🔬 實驗結果分析

📌 目標領域效能：

- LoRA 在 CPT (Code Pretraining) 中的表現不及完整微調。
- 在 IFT (Instruction Finetuning) 中，尤其是程式碼領域，LoRA 需要較高的秩來縮小與完整微調的差距。
- LoRA 在標準低秩設定下，通常需要更長的訓練時間，且效果仍遜於完整微調。
📌 來源領域遺忘：

- LoRA 在保留來源領域效能方面優於完整微調。
📌 學習-遺忘權衡：

- LoRA 在程式碼微調的權衡較佳。
- 完整微調在數學相關任務的權衡較優。
📌 超參數敏感度：

- LoRA 對學習率、目標模組選擇、秩和縮放因子極度敏感。


---

## 🔎 結論與應用建議

✅ LoRA 適用於：

- 記憶體資源受限的環境。
- 需要保持模型原始知識的場景。
- 針對特定應用的輕量級微調。
✅ 完整微調適用於：

- 需要學習大量新知識的場景，例如程式碼領域。
- 追求最佳效能，並有充足計算資源的情境。
⚠ 關鍵考量：

- 完整微調的權重變動通常不是低秩的，這對 LoRA 方法的假設構成挑戰。
- LoRA 需要細緻的超參數調整，以確保其效能能夠接近完整微調。


---
