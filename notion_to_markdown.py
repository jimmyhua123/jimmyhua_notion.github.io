import os
import requests
import datetime
import re
import glob
import unicodedata
from urllib.parse import urlparse

# ----------------------------------------------------------------------
# 1. è®€å– Notion Token & Page ID è¨­å®š
# ----------------------------------------------------------------------

NOTION_TOKEN = "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"
# NOTION_TOKEN = os.environ["NOTION_TOKEN"] 
ROOT_PAGE_ID = "166fbb857f9e80eba96ef0091d6ce244"  # ä½ çš„æœ€ä¸Šå±¤ Notion Page ID

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28"
}


def slugify(text):
    """
    è½‰æ›æ¨™é¡Œç‚ºæª”æ¡ˆåç¨±å‹å–„æ ¼å¼ï¼š
    - ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿ
    - è½‰æ›ç‚ºå°å¯«
    - ç©ºæ ¼è®Šæˆ "-"
    """
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'[^\w\s-]', '', text).strip().lower()
    return re.sub(r'[-\s]+', '-', text)

# ----------------------------------------------------------------------
# 2. å–å¾—é é¢æ¨™é¡Œ (é¸æ“‡ç”¨ retrieve_pageï¼Œæˆ–ç›´æ¥å¾ child_page["title"] å–)
# ----------------------------------------------------------------------
def retrieve_page_title(page_id: str) -> tuple:
    """
    ç²å– Notion é é¢æ¨™é¡Œï¼Œä¸¦ç”¢ç”Ÿ `slug`
    """
    url = f"https://api.notion.com/v1/pages/{page_id}"
    try:
        res = requests.get(url, headers=HEADERS)
        data = res.json()
        title_obj = data["properties"]["title"]["title"]
        if title_obj:
            page_title = title_obj[0]["plain_text"]
            return page_title, slugify(page_title)  # âš¡ï¸ å›å‚³ slug
    except (KeyError, IndexError, requests.exceptions.RequestException) as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–é é¢æ¨™é¡Œï¼š{e}")
    return "Untitled", "untitled"

# ----------------------------------------------------------------------
# 3. å–å¾—æŸé é¢ä¸‹çš„æ‰€æœ‰å€å¡Š (å«åˆ†é è™•ç†)
# ----------------------------------------------------------------------
def fetch_notion_blocks(page_id: str) -> list:
    """
    å›å‚³æ‰€æœ‰ blocksï¼ˆlistï¼‰ï¼Œä¸åŒ…å«å­é é¢ä¸‹å±¤
    """
    all_blocks = []
    base_url = "https://api.notion.com/v1/blocks"
    url = f"{base_url}/{page_id}/children"
    params = {}

    while True:
        resp = requests.get(url, headers=HEADERS, params=params)
        data = resp.json()
        for block in data.get("results", []):
            all_blocks.append(block)
            # è‹¥ block æœ‰å­å€å¡Šï¼Œåƒ…å°é image é¡å‹é€²è¡Œéè¿´ï¼ˆé¿å…åœ–ç‰‡é‡è¤‡ï¼‰
            if block.get("has_children", False) and block.get("type") != "image":
                child_blocks = fetch_notion_blocks(block["id"])
                all_blocks.extend(child_blocks)
        if data.get("has_more"):
            params["start_cursor"] = data["next_cursor"]
        else:
            break
    return all_blocks

# ----------------------------------------------------------------------
# æ–°å¢å‡½å¼ï¼šä¸‹è¼‰åœ–ç‰‡ä¸¦å„²å­˜åˆ°æœ¬æ©Ÿ
# ----------------------------------------------------------------------
def download_image(image_url: str, block_id: str) -> str:
    """
    ä¸‹è¼‰åœ–ç‰‡ä¸¦å„²å­˜åˆ°æœ¬æ©Ÿ images è³‡æ–™å¤¾ï¼Œå›å‚³åœ–ç‰‡çš„ç›¸å°è·¯å¾‘ (ä¾› Markdown ä½¿ç”¨)
    """
    images_dir = "images"
    if not os.path.exists(images_dir):
        os.makedirs(images_dir)

    # åˆ©ç”¨ urlparse è§£æåœ–ç‰‡ URLï¼Œå–å¾—æª”æ¡ˆè·¯å¾‘èˆ‡å‰¯æª”å
    parsed_url = urlparse(image_url)
    path = parsed_url.path
    ext = os.path.splitext(path)[1]
    if not ext:
        ext = ".jpg"  # é è¨­å‰¯æª”å

    local_filename = f"{block_id}{ext}"
    local_path = os.path.join(images_dir, local_filename)

    # è‹¥åœ–ç‰‡å°šæœªä¸‹è¼‰ï¼Œå‰‡é€²è¡Œä¸‹è¼‰
    if not os.path.exists(local_path):
        try:
            r = requests.get(image_url, stream=True, timeout=10)
            if r.status_code == 200:
                with open(local_path, "wb") as f:
                    for chunk in r.iter_content(1024):
                        f.write(chunk)
                print(f"ä¸‹è¼‰åœ–ç‰‡æˆåŠŸ: {local_path}")
            else:
                print(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {image_url}ï¼Œç‹€æ…‹ç¢¼: {r.status_code}")
        except Exception as e:
            print(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {image_url}ï¼ŒéŒ¯èª¤: {e}")
    else:
        print(f"åœ–ç‰‡å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰: {local_path}")

    # å›å‚³åœ–ç‰‡åœ¨ç¶²ç«™ä¸­çš„ç›¸å°è·¯å¾‘
    # æ­¤è™•æ¡ç”¨çµ•å°è·¯å¾‘ '/images/filename'ï¼Œè‹¥éœ€è¦ç›¸å°è·¯å¾‘è«‹è‡ªè¡Œèª¿æ•´
    return f"{{{{ site.baseurl }}}}/images/{local_filename}"

# ----------------------------------------------------------------------
# 4. å°‡å–®ä¸€ block è½‰æˆ Markdownï¼ˆå¿½ç•¥ child_pageï¼‰
# ----------------------------------------------------------------------


def rich_text_array_to_markdown(rich_text_array: list) -> str:
    md_text_parts = []
    inline_math_pattern = re.compile(r'\$(.+?)\$')
    
    for rt in rich_text_array:
        text_content = rt.get("plain_text", "")
        # é€²è¡Œæ›¿æ›ï¼šå°‡æ‰€æœ‰ $...$ æ›æˆ $$...$$
        new_text = inline_math_pattern.sub(lambda m: "$$" + m.group(1) + "$$", text_content)
        # å°å‡ºé™¤éŒ¯è³‡è¨Šï¼Œæª¢æŸ¥è½‰æ›å‰å¾Œçš„å·®ç•°
        print("åŸå§‹æ–‡æœ¬ï¼š", text_content)
        print("æ›¿æ›å¾Œï¼š", new_text)
        
        link_url = None
        if rt.get("href"):
            link_url = rt.get("href")
        elif rt.get("text") and rt["text"].get("link"):
            link_url = rt["text"]["link"].get("url")
        
        if link_url:
            md_text_parts.append(f"[{new_text}]({link_url})")
        else:
            md_text_parts.append(new_text)
    result = "".join(md_text_parts)
    print("æœ€çµ‚è½‰æ›çµæœï¼š", result)
    return result

def block_to_markdown(block: dict, article_title: str = "untitled") -> str:
    """
    å°‡å–®ä¸€ Notion block è½‰ç‚º Markdown çš„å­—ä¸²ã€‚
    ç¤ºç¯„å¸¸è¦‹çš„ block é¡å‹ï¼šparagraph, heading, list, equation, code, image, divider, quote, table ç­‰ã€‚
    """
    btype = block.get("type", "")
    # 1. æ®µè½ paragraph
    if btype == "paragraph":
        texts = block[btype].get("rich_text", [])
        paragraph_text = rich_text_array_to_markdown(texts)
        return paragraph_text + "\n\n"

    # 2. æ¨™é¡Œ heading_1 / heading_2 / heading_3
    elif btype == "heading_1":
        texts = block[btype].get("rich_text", [])
        heading_text = rich_text_array_to_markdown(texts)
        return f"# {heading_text}\n\n"

    elif btype == "heading_2":
        texts = block[btype].get("rich_text", [])
        heading_text = rich_text_array_to_markdown(texts)
        return f"## {heading_text}\n\n"

    elif btype == "heading_3":
        texts = block[btype].get("rich_text", [])
        heading_text = rich_text_array_to_markdown(texts)
        return f"### {heading_text}\n\n"

    # 3. æ¸…å–® bulleted_list_item / numbered_list_item
    elif btype == "bulleted_list_item":
        texts = block[btype].get("rich_text", [])
        list_text = rich_text_array_to_markdown(texts)
        if block.get("has_children", False):
            sub_blocks = fetch_notion_blocks(block["id"])
            sub_texts = [block_to_markdown(sub) for sub in sub_blocks]
            sub_content = "\n  ".join(sub_texts)
            return f"- {list_text}\n  {sub_content}\n"
        else:
            return f"- {list_text}\n"

    elif btype == "numbered_list_item":
        texts = block[btype].get("rich_text", [])
        list_text = rich_text_array_to_markdown(texts)
        if block.get("has_children", False):
            sub_blocks = fetch_notion_blocks(block["id"])
            sub_texts = [block_to_markdown(sub) for sub in sub_blocks]
            sub_content = "\n  ".join(sub_texts)
            return f"1. {list_text}\n  {sub_content}\n"
        else:
            return f"1. {list_text}\n"

    # 4. æ•¸å­¸æ–¹ç¨‹å¼ equation
    elif btype == "equation":
        equation_text = block[btype].get("expression", "")
        return f"$$\n{equation_text}\n$$\n\n"

    # 5. ç¨‹å¼ç¢¼ code
    elif btype == "code":
        texts = block[btype].get("rich_text", [])
        code_text = "".join(rich_text_array_to_markdown([t]) for t in texts)
        language = block[btype].get("language", "plaintext")
        return f"```{language}\n{code_text}\n```\n\n"

    # 6. åœ–ç‰‡ imageï¼ˆå„ªåŒ–åœ–ç‰‡è™•ç†ï¼šä¸‹è¼‰åœ–ç‰‡ä¸¦å¼•ç”¨æœ¬åœ°è·¯å¾‘ï¼‰
    elif btype == "image":
        image_data = block[btype]
        if image_data.get("type") == "external":
            url = image_data["external"].get("url", "")
        else:
            url = image_data["file"].get("url", "")
        local_url = download_image(url, block["id"])
        return f"![image]({local_url})\n\n"

    # 7. åˆ†éš”ç·š divider
    elif btype == "divider":
        return "---\n\n"

    # 8. å¼•è¨€ quote
    elif btype == "quote":
        texts = block[btype].get("rich_text", [])
        quote_text = rich_text_array_to_markdown(texts)
        return f"> {quote_text}\n\n"

    # 9. è¡¨æ ¼ table
    elif btype == "table":
        table_info = block.get("table", {})
        table_width = table_info.get("table_width", 3)
        if block.get("has_children", False):
            table_rows = fetch_notion_blocks(block["id"])
        else:
            return ""
        md_table = []
        for row in table_rows:
            if row["type"] == "table_row":
                cells = row["table_row"].get("cells", [])
                md_row = " | ".join(rich_text_array_to_markdown(cell) for cell in cells)
                md_table.append(f"| {md_row} |")
        if md_table:
            separator = "| " + " | ".join(["---"] * table_width) + " |"
            md_table.insert(1, separator)
        return "\n".join(md_table) + "\n\n"

    # è‹¥é‡åˆ° child_page / child_databaseï¼Œå‰‡äº¤ç”±å¤–å±¤éè¿´è™•ç†
    elif btype in ["child_page", "child_database"]:
        return ""

    # å…¶ä»–ä¸æ”¯æ´çš„ block é¡å‹ï¼Œå›å‚³ç©ºå­—ä¸²
    return ""

# ----------------------------------------------------------------------
# 5. éè¿´å‡½å¼ï¼šparse_and_export_recursively()
# ----------------------------------------------------------------------
processed_pages = set()  # å…¨åŸŸé›†åˆï¼Œç”¨ä¾†è¨˜éŒ„å·²è™•ç†çš„ page_id

def parse_and_export_recursively(page_id: str, parent_slug: str = None):
    global processed_pages

    if page_id in processed_pages:
        print(f"âš ï¸ é é¢ {page_id} å·²è™•ç†ï¼Œè·³éé‡è¤‡æ“ä½œ")
        return

    processed_pages.add(page_id)

    # å–å¾—æ¨™é¡Œèˆ‡ slug
    page_title, slug = retrieve_page_title(page_id)
    if parent_slug:
        slug = f"{parent_slug}-{slug}"

    # å–å¾—é é¢å…§å®¹ Blocks
    blocks = fetch_notion_blocks(page_id)
    page_markdown_parts = []
    child_pages = []

    for block in blocks:
        btype = block.get("type", "")
        if btype == "child_page":
            child_pages.append(block)
        else:
            page_markdown_parts.append(block_to_markdown(block, article_title=page_title))

    # åˆæˆ Markdown å…§å®¹
    page_markdown = "".join(page_markdown_parts)

    # è‹¥æ²’æœ‰å­é é¢å‰‡ç”Ÿæˆæ–‡ç« 
    if not child_pages:
        upsert_post_with_date_update(slug, page_title, page_markdown, categories=["NotionExport"])

    # éè¿´è™•ç†å­é é¢
    for child_block in child_pages:
        child_id = child_block["id"]
        parse_and_export_recursively(child_id, parent_slug=slug)


def upsert_post_with_date_update(slug, title, new_markdown, categories=None):
    if not os.path.exists("_posts"):
        os.makedirs("_posts")

    # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰è©²æ¨™é¡Œçš„æ–‡ç« 
    existing_files = glob.glob(f"_posts/*-{slug}.md")
    if existing_files:
        filename = existing_files[0]
        with open(filename, "r", encoding="utf-8") as f:
            old_full_content = f.read()
    else:
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        filename = f"_posts/{today_str}-{slug}.md"
        old_full_content = ""

    # åˆªé™¤é‡è¤‡æª”æ¡ˆ
    for file in existing_files:
        if file != filename:
            os.remove(file)
            print(f"âš ï¸ åˆªé™¤é‡è¤‡æª”æ¡ˆï¼š{file}")

    # æå–èˆŠçš„ front matter èˆ‡å…§å®¹
    match = re.search(r"(?s)^---(.*?)---(.*)$", old_full_content)
    if match:
        old_front = match.group(1).strip()
        old_body = match.group(2).strip()
    else:
        old_front = ""
        old_body = old_full_content.strip()

    # è¨­å®šæœ€æ–°æ—¥æœŸ
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    new_date = f"{today_str} 10:00:00 +0800"

    # æ›´æ–° front matterï¼ˆä¿ç•™å…¶ä»–æ¬„ä½ï¼Œä½†ä¸è¦†è“‹ dateï¼‰
    front_matter_dict = {
        "layout": "post",
        "title": f'"{title}"',
        "date": new_date,
        "categories": categories if categories else ["NotionExport"],
        "math": "true"
    }
    if old_front:
        for line in old_front.split("\n"):
            key, *value = line.split(":", 1)
            key = key.strip()
            # è‹¥ key ç‚º date å‰‡è·³éï¼Œé¿å…è¦†è“‹æ–°æ—¥æœŸ
            if key != "date" and value:
                front_matter_dict[key] = value[0].strip()

    # æœ€å¾Œå†é‡æ–°è¨­å®šä¸€æ¬¡ dateï¼Œç¢ºä¿ç‚ºæœ€æ–°æ—¥æœŸ
    front_matter_dict["date"] = new_date

    updated_front_matter = "---\n" + "\n".join(f"{key}: {value}" for key, value in front_matter_dict.items()) + "\n---\n"
    updated_full = updated_front_matter + "\n" + new_markdown.strip() + "\n"

    if old_body != new_markdown.strip():
        with open(filename, "w", encoding="utf-8") as f:
            f.write(updated_full)
        print(f"[UPDATE] {filename} å…§å®¹è®Šæ›´ï¼Œæ—¥æœŸå·²æ›´æ–°")
    else:
        print(f"[NO CHANGE] {filename} å…§å®¹æœªè®Šæ›´ï¼Œç„¡éœ€æ›´æ–°")

# ----------------------------------------------------------------------
# 7. Mainï¼šæŒ‡å®šæœ€ä¸Šå±¤é é¢IDï¼Œé–‹å§‹éè¿´
# ----------------------------------------------------------------------
def main():
    """
    ä¸»å‡½å¼ï¼šå¾ Notion ç²å–æ‰€æœ‰é é¢ï¼Œéè¿´è½‰æ›ç‚º Markdownï¼Œä¸¦å„²å­˜åˆ° _posts/ ç›®éŒ„ã€‚
    """
    print("ğŸš€ é–‹å§‹åŒ¯å‡º Notion å…§å®¹...")
    
    try:
        parse_and_export_recursively(ROOT_PAGE_ID)
        print("ğŸ‰ å…¨éƒ¨é é¢ï¼ˆå«å­é é¢ï¼‰åŒ¯å‡ºå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ç™¼ç”Ÿï¼š{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
