---
layout: post
title: "生成式 AI 應用開發的常見錯誤"
date: 2025-02-06 10:00:00 +0800
categories: ['NotionExport']
math: true
---

📌 文章來源 [https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html](https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html)

## ❶ 不該用生成式 AI 的場景，硬要用生成式 AI 🤖

大語言模型（LLM）確實強大，但它並不適用於所有場景。然而，許多人對這項技術的能力缺乏理解，強行將 LLM 用於不合適的應用，例如：

- 能源消耗最佳化
- 流量異常檢測
- 電量預測
- 病人營養不良檢測
這些場景更適合使用 傳統機器學習 或 專門演算法，而非 LLM。

🔹 我曾遇過公司想用 LLM 進行營運最佳化和異常檢測，結果發現資料全是數字型態。這類問題根本不應該用 LLM，而應該使用適合的數據分析工具或機器學習方法。

---

### ❷ 搞混「爛 AI 產品」與「笨 AI 模型」 🤦‍♂️

很多失敗案例並非因為 LLM 本身不夠聰明，而是因為 產品設計 和 AI 工程能力不足。

舉例來說，目前市面上的 AI 代碼助手，如：

- GitHub Copilot
- Cursor
- Windsurf
- Devin
這些產品大多使用相同的 LLM，真正的差異在於：

1. 產品設計是否優秀
1. 是否具備良好的 AI 工程能力
  - Prompt Chaining

  - 檢索增強生成（RAG）

  - 模型上下文管理

- Prompt Chaining
- 檢索增強生成（RAG）
- 模型上下文管理
如果沒有這些技術，無論模型多強，最終的產品體驗都會很糟糕。

📌 關鍵觀念：「原始智力」≠「智慧軟體系統」

LLM 只是基石，真正有效的 AI 系統還需要：

- 上下文管理
- 工具整合
- 成熟的工程化流程
這也符合 Berkeley AI Research (BAIR) 提出的 [The Shift from Models to Compound AI Systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)，即 AI 越來越依賴 多個組件協作，而非單純依賴 LLM。

---

### ❸ 一開始就搞得太複雜 🏗️

許多團隊過早地引入不必要的複雜技術，導致系統難以維護。例如：

❌ 不需要時就使用 Agent 框架

❌ 糾結於選擇向量資料庫，而忽略基礎需求

❌ 明明透過 Prompting 就足夠，卻堅持要 Fine-tuning

這些做法往往會：

- 增加開發難度
- 抽象掉關鍵細節
- 讓系統更難理解和除錯
📌 建議：先用最簡單的方法解決問題，確保技術選擇符合需求，而非為了技術而技術。

---

### ❹ 過度樂觀看待初期成功 🎢

許多 AI 團隊在早期取得不錯的成果後，容易產生過度樂觀的錯誤判斷。例如：

🔹 LinkedIn AI 產品開發經驗

- 從 0 到 80% 只花 1 個月
- 從 80% 到 95% 卻花了 4 個月
- 最後 10-20% 的優化往往最困難
🎯 重點：做出 Demo 很容易，但真正要上線的產品極具挑戰！

後期會遇到：

- 幻覺問題（Hallucination）
- 延遲
- 準確性與效能的權衡
- Prompt 設計
- 模型評估
🔹 千萬不要因為初期的成功，而忽視後期的挑戰！

---

### ❺ 忽視人工評估 🧐

目前許多 AI 團隊使用 LLM 自評 LLM（LLM-as-judge），雖然這種方式便利，但不能完全依賴。最優秀的 AI 團隊仍然依賴人工評估，他們會每天抽樣 30 - 1000 例進行檢查，以確保模型表現。

✅ 人工評估的重要性

1. 驗證 AI 評估結果的準確性
1. 了解實際用戶的使用情況
1. 及早發現異常模式
📌 建議：AI 評估 + 人工抽樣，雙管齊下才能確保模型可靠性！

---

### ❻ 盲目蒐集使用案例 📋

許多企業在 AI 數位轉型時，缺乏明確的目標，只是因為知道 LLM 很強，就盲目探索應用場景，導致：

❌ 天馬行空的黑客松，產出大量重複的小專案
❌ 過多聊天機器人與插件，影響 AI 團隊的專注力
❌ 最終得出「生成式 AI 投資報酬率不高」的結論

🔹 建議：

1. 確定核心業務需求
1. 建立清晰的 AI 應用策略
1. 專注在真正能帶來高價值的應用
這樣才能讓 AI 投資獲得最大回報，避免無謂的資源浪費。

---

## 🎯 總結：如何避免 AI 工程的 6 大陷阱？

| 陷阱 | 主要問題 | 解決方案 |
| --- | --- | --- |
| ❶ 濫用生成式 AI | LLM 不適用所有場景 | 使用專門的機器學習與演算法 |
| ❷ 以為 AI 產品爛是因為模型笨 | 其實是工程能力不足 | 強化 Prompting、RAG、上下文管理 |
| ❸ 一開始就搞得太複雜 | 過早引入不必要的工具 | 先用最簡單的方法解決問題 |
| ❹ 過度樂觀初期成功 | 低估最後 10-20% 的難度 | 預留足夠時間進行優化 |
| ❺ 忽視人工評估 | LLM 自評不夠準確 | 結合人工抽樣，提高評估準確性 |
| ❻ 盲目蒐集使用案例 | 缺乏明確策略，導致資源浪費 | 聚焦高價值應用，建立清晰 AI 策略 |

📌 AI 工程不僅是 LLM 的應用，還涉及上下文管理、產品設計、工程能力、評估機制與策略規劃。希望這些建議能幫助你在 AI 領域少走彎路，打造真正有價值的 AI 產品！🚀
